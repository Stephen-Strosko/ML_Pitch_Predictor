{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milti-Player Pitch Model\n",
    "This notebook contains models that will take pitch information for a list of players and will then train itself to predict future pitches that are thrown by any major league pitcher. This model is a more general model of the single-player model and is to be used to draw general conclusions about pitching trends.\n",
    "The notebook contains code for the following:\n",
    "1. Random Forest Model\n",
    "2. Gradient Boosting Model\n",
    "\n",
    "Note: Please see the single player model for parameter tuning guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:33.646Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from pybaseball import pitching_stats\n",
    "from pybaseball import playerid_lookup\n",
    "from pybaseball import statcast_pitcher\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:34.215Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block takes a list of pitchers (first name last name, with no commas separating names).\n",
    "# The list is saved in a text file and the name can be put for the file variable. There is no limit to the amount of names.\n",
    "file = 'example_player_list.txt'\n",
    "f = open(file)\n",
    "text = f.read().split()\n",
    "player_dict = {text[i]: text[i+1] for i in range(0, len(text), 2)}\n",
    "counter = 0\n",
    "for key, value in player_dict.items():\n",
    "    print(key)\n",
    "    id = playerid_lookup(value, key)\n",
    "    id_number = id.key_mlbam[0]\n",
    "    if counter < 1:\n",
    "        new_df = statcast_pitcher(start_dt='2010-01-01', end_dt='2017-11-07', player_id=id_number)\n",
    "        counter = counter + 2\n",
    "    if counter > 1:\n",
    "        old_df = statcast_pitcher(start_dt='2010-01-01', end_dt='2017-11-07', player_id=id_number)\n",
    "        new_df = pd.concat([old_df, new_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the data structure and provided features\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:34.806Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chooses the features that will be used in the model.\n",
    "df = new_df[['pitch_type', 'balls', 'strikes', 'stand', 'outs_when_up', 'inning', 'on_3b', 'on_2b', 'on_1b', 'at_bat_number', 'pitch_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:35.697Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replaces null values and maps some of the features to 1 and 0.\n",
    "df = df.replace('null', 0)\n",
    "df['on_1b'] = df['on_1b'].map(lambda x: 1 if x != 0 else 0)\n",
    "df['on_2b'] = df['on_2b'].map(lambda x: 1 if x != 0 else 0)\n",
    "df['on_3b'] = df['on_3b'].map(lambda x: 1 if x != 0 else 0)\n",
    "df['stand'] = df['stand'].map({'R': 1, 'L': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:36.798Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encodes binary variables for the ball/strike count. \n",
    "# Drops the features balls and strikes.\n",
    "df['zero_zero'] = ((df.balls == 0) & (df.strikes == 0)).map({True:1, False:0})\n",
    "df['zero_one'] = ((df.balls == 0) & (df.strikes == 1)).map({True:1, False:0})\n",
    "df['zero_two'] = ((df.balls == 0) & (df.strikes == 2)).map({True:1, False:0})\n",
    "df['one_zero'] = ((df.balls == 1) & (df.strikes == 0)).map({True:1, False:0})\n",
    "df['one_one'] = ((df.balls == 1) & (df.strikes == 1)).map({True:1, False:0})\n",
    "df['one_two'] = ((df.balls == 1) & (df.strikes == 2)).map({True:1, False:0})\n",
    "df['two_zero'] = ((df.balls == 2) & (df.strikes == 0)).map({True:1, False:0})\n",
    "df['two_one'] = ((df.balls == 2) & (df.strikes == 1)).map({True:1, False:0})\n",
    "df['two_two'] = ((df.balls == 2) & (df.strikes == 2)).map({True:1, False:0})\n",
    "df['three_zero'] = ((df.balls == 3) & (df.strikes == 0)).map({True:1, False:0})\n",
    "df['three_one'] = ((df.balls == 3) & (df.strikes == 1)).map({True:1, False:0})\n",
    "df['three_two'] = ((df.balls == 3) & (df.strikes == 2)).map({True:1, False:0})\n",
    "df = df.drop('balls', axis=1)\n",
    "df = df.drop('strikes', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:37.778Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finds all pitch types that occur less than the variable percentage.\n",
    "# This cell block allows you to modify how many pitch types will be predicted in your model - modify the percentage variable.\n",
    "df = df[df.pitch_type != 0]\n",
    "z = df.pitch_type.value_counts() / len(df)\n",
    "percentage = 0.05\n",
    "drop_list = [value for value in z if value < percentage]\n",
    "\n",
    "# Drops rows with pitch types that do not occur often enough\n",
    "for k, v in z.items():\n",
    "    for i in drop_list:\n",
    "        if v == i:\n",
    "            df = df[df.pitch_type != k]\n",
    "            \n",
    "# Prints the pitch types and the amount of each pitch type that remains             \n",
    "df.pitch_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:58:40.603Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optional code that allows the user to have equal amounts of data for each pitch type (suggested for one-pitch heavy players).\n",
    "# Adjust the baseline_value variable to change how occurances you want for each pitch type.\n",
    "baseline_value = 20000\n",
    "pitch_list = df.pitch_type.unique()\n",
    "df_empty = pd.DataFrame()\n",
    "counter = 1\n",
    "for i in pitch_list:\n",
    "    df_pitch = df.loc[df['pitch_type'] == i]\n",
    "    df_pitch = df_pitch.head(baseline_value)\n",
    "    if counter == 1:\n",
    "        df_pitch_final = pd.concat([df_empty, df_pitch])\n",
    "        counter = counter + 1\n",
    "    else:\n",
    "        df_pitch_final = pd.concat([df_pitch_final, df_pitch]) \n",
    "df = df_pitch_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:42.082Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates the random forest model and fits the data.\n",
    "# Change the paramaters - max_depth, n_estimators, min_samples_leaf - to achieve optimal results.\n",
    "# Change the test_size variable to adjust how much data is held out to test your model.\n",
    "y, label = pd.factorize(df['pitch_type'])\n",
    "X = df.drop('pitch_type', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "rfs = RandomForestClassifier()\n",
    "rfs.fit(X_train, y_train)\n",
    "results = rfs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:42.906Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shows the feature importance for each input into the model.\n",
    "list(zip(X_train, rfs.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:43.856Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confustion matrix displayed to show how many true positives were classified.\n",
    "confusion_matrix(y_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:44.423Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy score shows the rate that the model correctly classified the test data.\n",
    "accuracy_score(y_test, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gradient Booster\n",
    "Note: It is recommended with the multi-player gradient booster model to use the optional sample size cell that gives equal amounts of each pitch. Otherwise the model will tend to classify everything as a fastball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:46.136Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates the gradient booster model and fits the data.\n",
    "# Change the paramater n_estimators and learning_rate for better results.\n",
    "# Change the test_size variable to adjust how much data is held out to test your model.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "gbs = GradientBoostingClassifier(n_estimators=1000)\n",
    "gbs.fit(X_train, y_train)\n",
    "results = gbs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:46.967Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shows the feature importance for each input into the model.\n",
    "list(zip(X_train, rfs.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:47.509Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confustion matrix displayed to show how many true positives were classified.\n",
    "confusion_matrix(y_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-26T01:59:48.109Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy score shows the rate that the model correctly classified the test data.\n",
    "accuracy_score(y_test, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
