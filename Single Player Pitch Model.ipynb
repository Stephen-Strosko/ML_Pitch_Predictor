{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Player Pitch Model\n",
    "This notebook contains models that will take pitch information for a single player and will then train itself to predict future pitches that are thrown by that same player.\n",
    "The notebook contains code for the following:\n",
    "1. Random Forest Model\n",
    "2. Gradient Boosting Model\n",
    "3. Parameter Tuning Guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:51:40.966887Z",
     "start_time": "2017-11-21T23:51:30.269700Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from pybaseball import pitching_stats\n",
    "from pybaseball import playerid_lookup\n",
    "from pybaseball import statcast_pitcher\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:51:57.516218Z",
     "start_time": "2017-11-21T23:51:40.969784Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrieve player data from baseballsavant via pybaseball api.\n",
    "# Change the four variables below to select a specific player and date range.\n",
    "first_name = 'felix'\n",
    "last_name = 'hernandez'\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2017-11-07'\n",
    "id = playerid_lookup(last_name, first_name)\n",
    "id_number = id.key_mlbam[0]\n",
    "felix = statcast_pitcher(start_dt=start_date, end_dt=end_date, player_id=id_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:51:57.526245Z",
     "start_time": "2017-11-21T23:51:57.519226Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chooses the features that will be used in the model.\n",
    "df = felix[['pitch_type', 'balls', 'strikes', 'stand', 'outs_when_up', 'inning', 'on_3b', 'on_2b', 'on_1b', 'at_bat_number', 'pitch_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:51:57.600477Z",
     "start_time": "2017-11-21T23:51:57.528250Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replaces null values and maps some of the features to 1 and 0.\n",
    "df = df.replace('null', 0)\n",
    "df['on_1b'] = df['on_1b'].map(lambda x: 1 if x != 0 else 0)\n",
    "df['on_2b'] = df['on_2b'].map(lambda x: 1 if x != 0 else 0)\n",
    "df['on_3b'] = df['on_3b'].map(lambda x: 1 if x != 0 else 0)\n",
    "df['stand'] = df['stand'].map({'R': 1, 'L': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:51:57.653151Z",
     "start_time": "2017-11-21T23:51:57.602449Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a new feature, ball_strike, that represents the ball/strike count. \n",
    "# Drops the features balls and strikes.\n",
    "conditions = [\n",
    "    (df['balls'] == 0) & (df['strikes'] == 0),\n",
    "    (df['balls'] == 1) & (df['strikes'] == 0),\n",
    "    (df['balls'] == 2) & (df['strikes'] == 0),\n",
    "    (df['balls'] == 3) & (df['strikes'] == 0),\n",
    "    (df['balls'] == 0) & (df['strikes'] == 1),\n",
    "    (df['balls'] == 0) & (df['strikes'] == 2),\n",
    "    (df['balls'] == 1) & (df['strikes'] == 1),\n",
    "    (df['balls'] == 1) & (df['strikes'] == 2),\n",
    "    (df['balls'] == 2) & (df['strikes'] == 1),\n",
    "    (df['balls'] == 2) & (df['strikes'] == 2),\n",
    "    (df['balls'] == 3) & (df['strikes'] == 1),\n",
    "    (df['balls'] == 3) & (df['strikes'] == 2),\n",
    "]\n",
    "choices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "df['ball_strike']  = np.select(conditions, choices)\n",
    "df = df.drop('balls', axis=1)\n",
    "df = df.drop('strikes', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:51:57.720274Z",
     "start_time": "2017-11-21T23:51:57.655100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finds all pitch types that occur less than the variable percentage.\n",
    "# This cell block allows you to modify how many pitch types will be predicted in your model - modify the percentage variable.\n",
    "df = df[df.pitch_type != 0]\n",
    "z = df.pitch_type.value_counts() / len(df)\n",
    "percentage = 0.15\n",
    "drop_list = [value for value in z if value < percentage]\n",
    "\n",
    "# Drops rows with pitch types that do not occur often enough\n",
    "for k, v in z.items():\n",
    "    for i in drop_list:\n",
    "        if v == i:\n",
    "            df = df[df.pitch_type != k]\n",
    "            \n",
    "# Prints the pitch types and the amount of each pitch type that remains             \n",
    "df.pitch_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optional code that allows the user to have equal amounts of data for each pitch type (suggested for one-pitch heavy players).\n",
    "# Adjust the baseline_value variable to change how occurances you want for each pitch type.\n",
    "baseline_value = 3000\n",
    "pitch_list = df.pitch_type.unique()\n",
    "df_empty = pd.DataFrame()\n",
    "counter = 1\n",
    "for i in pitch_list:\n",
    "    df_pitch = df.loc[df['pitch_type'] == i]\n",
    "    df_pitch = df_pitch.head(baseline_value)\n",
    "    if counter == 1:\n",
    "        df_pitch_final = pd.concat([df_empty, df_pitch])\n",
    "        counter = counter + 1\n",
    "    else:\n",
    "        df_pitch_final = pd.concat([df_pitch_final, df_pitch]) \n",
    "df = df_pitch_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T00:40:13.285879Z",
     "start_time": "2017-11-22T00:40:13.082213Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates the random forest model and fits the data.\n",
    "# Change the paramaters - max_depth, n_estimators, min_samples_leaf - to achieve optimal results.\n",
    "# Change the test_size variable to adjust how much data is held out to test your model.\n",
    "y, label = pd.factorize(df['pitch_type'])\n",
    "X = df.drop('pitch_type', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "rfs = RandomForestClassifier()\n",
    "rfs.fit(X_train, y_train)\n",
    "results = rfs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:57:06.619231Z",
     "start_time": "2017-11-21T23:57:06.507412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shows the feature importance for each input into the model.\n",
    "list(zip(X_train, rfs.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:57:14.611000Z",
     "start_time": "2017-11-21T23:57:14.596930Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confustion matrix displayed to show how many true positives were classified.\n",
    "confusion_matrix(y_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:57:23.887044Z",
     "start_time": "2017-11-21T23:57:23.879023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy score shows the rate that the model correctly classified the test data.\n",
    "accuracy_score(y_test, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:52:26.673564Z",
     "start_time": "2017-11-21T23:52:21.640413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates the gradient booster model and fits the data.\n",
    "# Change the paramater n_estimators and learning_rate for better results.\n",
    "# Change the test_size variable to adjust how much data is held out to test your model.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "gbs = GradientBoostingClassifier()\n",
    "gbs.fit(X_train, y_train)\n",
    "results = gbs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:52:26.684596Z",
     "start_time": "2017-11-21T23:52:26.675571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shows the feature importance for each input into the model.\n",
    "list(zip(X_train, rfs.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:52:26.716682Z",
     "start_time": "2017-11-21T23:52:26.687604Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confustion matrix displayed to show how many true positives were classified.\n",
    "confusion_matrix(y_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T23:52:26.731721Z",
     "start_time": "2017-11-21T23:52:26.719690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy score shows the rate that the model correctly classified the test data.\n",
    "accuracy_score(y_test, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV - Random Forest\n",
    "- GridSearchCV is a good way to test how multiple parameters intereact when adjusted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T00:01:45.589680Z",
     "start_time": "2017-11-22T00:01:45.584688Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sets up the variables and values for the GridSearchCV - all can be changed.\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 700],\n",
    "    #'max_features': ['sqrt', 'log2'],\n",
    "    #'criterion' : ['gini', 'entropy'],\n",
    "    #'max_depth' : [4, 8, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T00:02:52.625329Z",
     "start_time": "2017-11-22T00:01:46.459868Z"
    }
   },
   "outputs": [],
   "source": [
    "# Runs the GridSearchCV\n",
    "CV_rfs = GridSearchCV(estimator=rfs, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "CV_rfs.fit(X_train, y_train)\n",
    "CV_rfs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T00:03:04.933682Z",
     "start_time": "2017-11-22T00:03:03.653278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Executes the random forest model with the suggested parameters and prints the accuracy score.\n",
    "results = CV_rfs.predict(X_test)\n",
    "accuracy_score(y_test, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV - Gradient Booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T21:05:30.953742Z",
     "start_time": "2017-11-21T21:05:30.946724Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sets up the variables and values for the GridSearchCV - all can be changed.\n",
    "param_grid = { \n",
    "    'learning_rate' : [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators' : [10, 25, 50, 100],\n",
    "    'max_depth' : [3, 5, 10],\n",
    "    'criterion' : ['friedman_mse', 'mse', 'mae'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-21T21:05:31.473Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Runs the GridSearchCV\n",
    "# Add verbose=10 to see the progress that this cell is making, could take a bit to execute.\n",
    "CV_gbs = GridSearchCV(estimator=gbs, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "CV_gbs.fit(X_train, y_train)\n",
    "CV_gbs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T21:05:00.262124Z",
     "start_time": "2017-11-21T21:05:00.204975Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prints a pandas dataframe that shows all of the grid search results. Allows the user to see what parameters actually impact the model robustly.\n",
    "pd.DataFrame(CV_gbs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T21:05:03.917106Z",
     "start_time": "2017-11-21T21:05:03.884018Z"
    }
   },
   "outputs": [],
   "source": [
    "# Executes the random forest model with the suggested parameters and prints the accuracy score.\n",
    "results = CV_gbs.predict(X_test)\n",
    "accuracy_score(y_test, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual parameter tuning based on accuracy score - Random Forest\n",
    "- This can be used to see trends in how certain variables impact the model as well as finding interesting values to plug into the gridsearchcv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T19:35:02.921882Z",
     "start_time": "2017-11-21T19:34:42.294430Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of estimators in the model.\n",
    "score = []\n",
    "for number in range(1, 50):\n",
    "    tree = RandomForestClassifier(n_estimators=number)\n",
    "    tree.fit(X_train, y_train)\n",
    "    results = tree.predict(X_test)\n",
    "    score.append(accuracy_score(y_test, results))\n",
    "plt.plot(np.arange(1,50,1),score)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('accuracy_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T19:35:08.560621Z",
     "start_time": "2017-11-21T19:35:07.758512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Max amount of splits for each tree in the model.\n",
    "score = []\n",
    "for depth in range(1,11):\n",
    "    tree = RandomForestClassifier(max_depth=depth)\n",
    "    tree.fit(X_train, y_train)\n",
    "    results = tree.predict(X_test)\n",
    "    score.append(accuracy_score(y_test, results))\n",
    "plt.plot(np.arange(1,11,1),score)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T19:35:19.125082Z",
     "start_time": "2017-11-21T19:35:17.295112Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many features are allowed to be used in each tree.\n",
    "score = []\n",
    "for number in range(1,9):\n",
    "    tree = RandomForestClassifier(max_features=number)\n",
    "    tree.fit(X_train, y_train)\n",
    "    results = tree.predict(X_test)\n",
    "    score.append(accuracy_score(y_test, results))\n",
    "plt.plot(np.arange(1,9,1),score)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('accuracy_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T19:35:56.628530Z",
     "start_time": "2017-11-21T19:35:40.526892Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many samples required for a leaf node.\n",
    "score = []\n",
    "for number in range(1,200):\n",
    "    tree = RandomForestClassifier(min_samples_leaf=number)\n",
    "    tree.fit(X_train, y_train)\n",
    "    results = tree.predict(X_test)\n",
    "    score.append(accuracy_score(y_test, results))\n",
    "plt.plot(np.arange(1,200,1),score)\n",
    "plt.xlabel('min_samples_leaf')\n",
    "plt.ylabel('accuracy_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curves - Random Forest\n",
    "- Good for see your true positive rate for each pitch type. The more area under the curve the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T00:40:24.784176Z",
     "start_time": "2017-11-22T00:40:24.750087Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the y_testb and y_pred_prob arrays.\n",
    "# Adjust the variable pitch amount to equal the number of unique pitches your model is predicting\n",
    "pitch_amount = 4\n",
    "y_testb = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "y_pred_prob = rfs.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T00:40:25.320452Z",
     "start_time": "2017-11-22T00:40:25.119355Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plots the ROC curves and creates a legend with the proper labels.\n",
    "fprs = []\n",
    "tprs = []\n",
    "for i in range(0, pitch_amount):\n",
    "    fpr, tpr, thresholds = roc_curve(y_testb[:,i], 1-y_pred_prob[:,i])\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "colors = ['y', 'g', 'r', 'b', 'm', 'c', 'k', 'w']\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "for i in range(0, pitch_amount):\n",
    "    plt.plot(fprs[i], tprs[i], c=colors[i], label=label[i])\n",
    "plt.legend()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
